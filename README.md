# LLM-study

# function calling
事前に定義した関数を必要に応じて呼び出し、関数の実行結果を元に回答を生成させるもの。

ユーザの質問から文章を解析して必要な関数を呼び出して、必要情報を付加して解答を生成する

- メリット
    - 外部のデータベースにアクセス結果をもとに回答できるようになる

- 流れ
    1. 関数定義
    2. プロンプトと関数の送信
        - ユーザのプロンプトと同時に作成した関数のリストをAPIに送信
    3. モデルの判断
        - モデルで学習された内容のみで解答を作成するか、関数を使うべきかを判断する
    4. 関数の実行
        - もし、関数を実行すべきと判断した場合は、関数を実行するための引数を辞書型のデータで返す。そのデータをもとにクライアント側で関数を実行して、その結果を返す
    5. 関数の出力結果に基づく応答
        - 関数の実行結果を加えて、最終的な解答を生成して、ユーザに返す

### ざっくりイメージ（引用）
<img src="image.png" width=50%>

# RAG(Retrieval-Augmented Generation)
外部の知識ベースから事実を検索して、最新の正確な情報に基づいて大規模言語モデル（LLM）に回答を生成させることで、ユーザーの洞察をLLMの生成プロセスに組み込むというAIフレームワークです
### ざっくりイメージ([引用](https://note.com/mizupe/n/nd5687d5a785b))
<img src="image-1.png" width=50%>

# LangChain