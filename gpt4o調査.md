## GPT4o APIでできること
- テキストと画像処理が可能
- 音声処理の機能はまだ、提供されていない
- 覚機能を通じて音声なしのビデオを理解できる。
    - ビデオをフレームに変換する必要がある(1秒あたり2 ~ 4フレーム)

## できないこと
- 5/14現在　画像生成はサポートされていない。やりたい場合はDALL-E3　APIを利用する必要がある
- 音声処理機能はまだ提供されていない→Whisperを使って代用するしかない


## 良いところ
- 高い知能：
  - テキスト、推論、コーディング能力においてGPT-4 Turboレベルのパフォーマンスを提供
  - 多言語、音声、視覚の能力でも新たな高水準を設定
  - 英語以外の言語においても優れた性能を発揮しているらしい
  ### GPT-4oと他モデル（Meta、Google）の音声翻訳のパフォーマンスを比較
  ![GPT-4oと他モデル（Meta、Google）の音声翻訳のパフォーマンスを比較](https://vnext.co.jp/uploads/2024/06/e29b5daf105e83f04071b0cc15656837.png)

- 2倍の反応速度：
  - GPT-4 Turboに比べ、トークン生成速度が2倍になりました
- 50％安い価格：
  - 入力トークンと出力トークンの両方において、GPT-4 Turboより50％安価です
- 5倍高いレート制限：
  - GPT-4 Turboに比べてレート制限が5倍になり、最大毎分1000万トークンまで可能です
- 視覚能力が改善：
  - ほとんどのタスクにおいて視覚能力が向上しました
- 非英語言語の能力が改善：
  - 非英語言語の処理能力が向上し、非英語テキストをより効率的にトークン化する新しいトークナイザーを使用しています


## コスト比較

| モデル          | 100万トークン当たりの料金（入力） | 100万トークン当たりの料金（出力） | 150×150ピクセル画像の生成料金（試算）     |
|-----------------|-----------------------------------|-----------------------------------|-----------------------------------------|
| GPT-3.5 Turbo   | 0.5ドル（約75円）                  | 1.5ドル（約225円）                 | 対応なし                                  |
| GPT-4           | 30ドル（約450円）                  | 60ドル（約9,000円）                | 対応なし                                  |
| GPT-4 Turbo     | 10ドル（約1,500円）                | 30ドル（約4,500円）                | 0.00255ドル（約0.38円）                  |
| GPT-4o          | 5ドル（約750円）                   | 15ドル（約2,250円）                | 0.001275ドル（約0.19円）                 |


## 試してみたいこと
- 画像系
    - 物体認識
        - https://zenn.dev/mattyamonaca/articles/6dc8fd4536fd97
    - 画像認識
        - レシートの仕分けとかに使えるかもね
    - ここに載っていることを試せば良いのでは？
    - https://weel.co.jp/media/innovator/gpt-4o-usage-examples/

## 調査タスク一覧
- 自然言語
    - 文章要約　できる
    - 質問応答　できる
    - 翻訳 できる
        - 英語->日本語：良いニュアンスで返してくれているような気がする(gpt4o vs gpt3.5turbo) 返信速度も4oが10秒ほど早かった
        - 韓国語->日本語：3.5に比べて正しく翻訳、ニュアンスも人間が訳した感じがしている
    - コンテンツ生成　できる
        - 画像を食べさせることでより充実したコンテンツを生成できそう。
        - 0ベースでもそれなりのものを作ることはできるが、画像などで追加コンテンツを与えるのが良さそう
    - トピックモデル　できる
        - GPT3.5に比べて、想像力が豊かな気がする
    - 文書分類　まだ試せていないができそう
        - 何を入力に何を出力したらこれができたとなるだろうか？
    - 検索　
        - apiではリアルタイム検索は不可 GUIなら可能
    - 物語生成　できる(ここは主観ですが、)
        - 話の流れやオチの付け方などはいい感じにできている。若干、文脈が？っとなる時があるが、3.5よりはだいぶ良い作品が作れそう？
    
- 計算問題
    - 簡単な数学問題　正解
    - 簡単な微分　正解
    - 早稲田の数学確率問題
        - ゼロショット　不正解
        - 解法を教えてあげると　正解　←ヒントをあげすぎたかもしれないが

- 画像処理(ocr技術がだいぶ上がっているような、、、)
    - 

- fine turning
    - 現在はGUI上で一応可能だが、apiではできないと思われる(source : https://help.openai.com/en/articles/7127982-can-i-fine-tune-gpt-4o-or-gpt-4)

### メモ
gpt4oで遂行できるタスクに種類に幅があるのではないか、と思っています。
ほかのLLMでは、
テキスト分類や
チャット、
言い換えなどのタスクが遂行できます。
ほかには、なんらかの学習モデルを構築できるのか、そこはRAGで対応するのが良いのか、というあたりです。
もし可能であれば、①タスクの幅、②モデル構築の考え方を少し深ぼっていただきたいです。


